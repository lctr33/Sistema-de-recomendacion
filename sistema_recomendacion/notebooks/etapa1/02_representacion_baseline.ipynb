{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410cdd3d",
   "metadata": {},
   "source": [
    "# Representación baseline: TF-IDF y N-gramas\n",
    "En este cuaderno generamos las representaciones del baseline exigido por la rúbrica: un modelo basado en N-gramas/TF-IDF construido sobre las reseñas limpias. También dejamos espacio para comparar contra embeddings (Word2Vec) como alternativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b7a97",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "- Cargar los datos procesados (train/dev/test) generados en el notebook anterior.\n",
    "- Construir una representación TF-IDF con N-gramas como baseline requerido.\n",
    "- Analizar la cobertura del vocabulario y validar la sparsidad de la matriz.\n",
    "- Guardar las matrices/del vectorizador para reutilizarlas en el notebook de modelado.\n",
    "- Dejar notas sobre la comparación futura con embeddings (Word2Vec/Sentence-BERT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ef7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/lctr/SEMESTRES/SEMESTRE_5/MINERIA_DE_TEXTO/PROYECTO\")\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from sistema_recomendacion.src.features.ngram_representation import build_tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761ab4e",
   "metadata": {},
   "source": [
    "## Carga de datos procesados\n",
    "Utilizamos los archivos generados en el notebook anterior (`books_ratings_clean.csv`, `ratings_train/dev/test.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d007ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_time</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>book_title_key</th>\n",
       "      <th>rating_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>AZUNT3QP2CWTL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Have you ever watched the fairies when the rai...</td>\n",
       "      <td>Although the new cover looks more like a Book ...</td>\n",
       "      <td>silver pennies</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>AWVWX5F3YEJKZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Found again...</td>\n",
       "      <td>This book was given to me over 30 years ago by...</td>\n",
       "      <td>silver pennies</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0786280670</td>\n",
       "      <td>AE3SEXFJCQLJQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>Meanspirited woman</td>\n",
       "      <td>The writing was okayish... But these details f...</td>\n",
       "      <td>julie and julia: 365 days, 524 recipes, 1 tiny...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000G167FA</td>\n",
       "      <td>AAFZZHA2I598B</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1969-12-31 23:59:59</td>\n",
       "      <td>An incomparable children's classic</td>\n",
       "      <td>This book of children's poems has been enjoyed...</td>\n",
       "      <td>silver pennies</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00005O4HA</td>\n",
       "      <td>A3RTKL9KB8KLID</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1996-08-17 00:00:00</td>\n",
       "      <td>The best mystery novel I have ever read</td>\n",
       "      <td>I have been a mystery reader for decades, and ...</td>\n",
       "      <td>playing for the ashes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_id         user_id  rating          review_time  \\\n",
       "0  B000G167FA   AZUNT3QP2CWTL     5.0  1969-12-31 23:59:59   \n",
       "1  B000G167FA   AWVWX5F3YEJKZ     5.0  1969-12-31 23:59:59   \n",
       "2  0786280670   AE3SEXFJCQLJQ     1.0  1969-12-31 23:59:59   \n",
       "3  B000G167FA   AAFZZHA2I598B     5.0  1969-12-31 23:59:59   \n",
       "4  B00005O4HA  A3RTKL9KB8KLID     5.0  1996-08-17 00:00:00   \n",
       "\n",
       "                                      review_summary  \\\n",
       "0  Have you ever watched the fairies when the rai...   \n",
       "1                                     Found again...   \n",
       "2                                 Meanspirited woman   \n",
       "3                 An incomparable children's classic   \n",
       "4            The best mystery novel I have ever read   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Although the new cover looks more like a Book ...   \n",
       "1  This book was given to me over 30 years ago by...   \n",
       "2  The writing was okayish... But these details f...   \n",
       "3  This book of children's poems has been enjoyed...   \n",
       "4  I have been a mystery reader for decades, and ...   \n",
       "\n",
       "                                      book_title_key  rating_normalized  \n",
       "0                                     silver pennies                1.0  \n",
       "1                                     silver pennies                1.0  \n",
       "2  julie and julia: 365 days, 524 recipes, 1 tiny...                0.0  \n",
       "3                                     silver pennies                1.0  \n",
       "4                              playing for the ashes                1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dir = PROJECT_ROOT / \"sistema_recomendacion\" / \"data\" / \"processed\"\n",
    "ratings_train = pd.read_csv(processed_dir / \"ratings_train.csv\")\n",
    "ratings_dev = pd.read_csv(processed_dir / \"ratings_dev.csv\")\n",
    "ratings_test = pd.read_csv(processed_dir / \"ratings_test.csv\")\n",
    "ratings_clean = pd.read_csv(processed_dir / \"books_ratings_clean.csv\")\n",
    "\n",
    "ratings_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d357cff",
   "metadata": {},
   "source": [
    "## Construcción de corpus textual\n",
    "Concatenamos el texto de reseñas y resúmenes para alimentar al vectorizador TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa42140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus train: 1,036,854 documentos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Have you ever watched the fairies when the rai...\n",
       "1    Found again... This book was given to me over ...\n",
       "2    Meanspirited woman The writing was okayish... ...\n",
       "3    An incomparable children's classic This book o...\n",
       "4    The best mystery novel I have ever read I have...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_corpus(df: pd.DataFrame) -> pd.Series:\n",
    "    return (df[\"review_summary\"].fillna(\"\") + \" \" + df[\"review_text\"].fillna(\" \")).str.strip()\n",
    "\n",
    "corpus_train = build_corpus(ratings_train)\n",
    "corpus_dev = build_corpus(ratings_dev)\n",
    "corpus_test = build_corpus(ratings_test)\n",
    "\n",
    "print(f\"Corpus train: {len(corpus_train):,} documentos\")\n",
    "corpus_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eb7ad",
   "metadata": {},
   "source": [
    "## Vectorización TF-IDF (baseline)\n",
    "Entrenamos un vectorizador sobre el corpus de entrenamiento usando unigramas y bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bc40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer, X_train = build_tfidf_matrix(\n",
    "    corpus_train,\n",
    "    ngram_range=(1, 2),   # empieza con unigramas\n",
    "    min_df=10,\n",
    "    max_df=0.5,\n",
    "    max_features=100_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba75d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar tfidf_vectorizer.transform(corpus_dev) y tfidf_vectorizer.transform(corpus_test) para obtener X_dev y X_test\n",
    "X_dev = tfidf_vectorizer.transform(corpus_dev)\n",
    "X_test = tfidf_vectorizer.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b074488",
   "metadata": {},
   "source": [
    "## Análisis rápido de la representación\n",
    "Revisamos vocabulario, sparsity y términos más frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813c2a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 100,000\n",
      "Train matrix density: 0.000942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quot          19808.796875\n",
       "story         17801.042969\n",
       "great         14668.979492\n",
       "like          14047.493164\n",
       "good          13960.112305\n",
       "time          12840.038086\n",
       "books         12764.720703\n",
       "novel         12689.014648\n",
       "just          12523.813477\n",
       "reading       12229.538086\n",
       "life          12130.949219\n",
       "love          11243.894531\n",
       "characters    10961.800781\n",
       "people        10034.844727\n",
       "really        10013.317383\n",
       "best           9036.454102\n",
       "way            8956.058594\n",
       "world          8942.403320\n",
       "written        8571.416016\n",
       "think          8388.578125\n",
       "dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tfidf_vectorizer.vocabulary_)\n",
    "sparsity = 1 - (X_train.nnz / (X_train.shape[0] * X_train.shape[1]))\n",
    "\n",
    "print(f\"Vocab size: {vocab_size:,}\")\n",
    "print(f\"Train matrix density: {(1 - sparsity):.6f}\")\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "top_indices = X_train.sum(axis=0).A1.argsort()[::-1][:20]\n",
    "top_terms = pd.Series(X_train.sum(axis=0).A1[top_indices], index=feature_names[top_indices])\n",
    "top_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cbeed0",
   "metadata": {},
   "source": [
    "## Persistencia para el modelo baseline\n",
    "Guardamos el vectorizador y las matrices (en formato `.npz`) para el notebook `03_modelo_baseline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fb88b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/home/lctr/SEMESTRES/SEMESTRE_5/MINERIA_DE_TEXTO/PROYECTO/sistema_recomendacion/data/processed/tfidf_vectorizer.joblib'),\n",
       " PosixPath('/home/lctr/SEMESTRES/SEMESTRE_5/MINERIA_DE_TEXTO/PROYECTO/sistema_recomendacion/data/processed/X_train_tfidf.npz'),\n",
       " PosixPath('/home/lctr/SEMESTRES/SEMESTRE_5/MINERIA_DE_TEXTO/PROYECTO/sistema_recomendacion/data/processed/X_dev_tfidf.npz'),\n",
       " PosixPath('/home/lctr/SEMESTRES/SEMESTRE_5/MINERIA_DE_TEXTO/PROYECTO/sistema_recomendacion/data/processed/X_test_tfidf.npz'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dir = PROJECT_ROOT / \"sistema_recomendacion\" / \"data\" / \"processed\"\n",
    "vectorizer_path = features_dir / \"tfidf_vectorizer.joblib\"\n",
    "train_matrix_path = features_dir / \"X_train_tfidf.npz\"\n",
    "dev_matrix_path = features_dir / \"X_dev_tfidf.npz\"\n",
    "test_matrix_path = features_dir / \"X_test_tfidf.npz\"\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
    "sparse.save_npz(train_matrix_path, X_train)\n",
    "sparse.save_npz(dev_matrix_path, X_dev)\n",
    "sparse.save_npz(test_matrix_path, X_test)\n",
    "\n",
    "vectorizer_path, train_matrix_path, dev_matrix_path, test_matrix_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cf841",
   "metadata": {},
   "source": [
    "## Próximos pasos / Comparativa con embeddings\n",
    "- Probar un modelo Word2Vec entrenado sobre el corpus limpio y comparar métricas con el baseline TF-IDF.\n",
    "- Explorar embeddings preentrenados (FastText, Sentence-BERT) como representación alternativa para cumplir la rúbrica.\n",
    "- Evaluar si la combinación TF-IDF + embeddings mejora el rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
